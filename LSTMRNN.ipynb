{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"OqsnEgm7AMV6","colab_type":"text"},"cell_type":"markdown","source":["\n"," ### Генерация текста с помощью LSTM RNN на примере пацанских цитат/юморесок.\n","\n"]},{"metadata":{"id":"8yMldw_Ki0FK","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import LSTM, Dense, Dropout, CuDNNLSTM, Bidirectional\n","from keras.callbacks import LambdaCallback, ModelCheckpoint\n","from keras.models import Sequential, load_model\n","import keras.utils as ku \n","import numpy as np\n","import random\n","import sys\n","import io"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YE1CoF0REcKT","colab_type":"text"},"cell_type":"markdown","source":["### Настройки"]},{"metadata":{"id":"-mWcNz_2EbR2","colab_type":"code","colab":{}},"cell_type":"code","source":["filepath = 'h2.txt'\n","weights_path = 'weights.hdf5'\n","new_model = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HbKFP2JjA4KR","colab_type":"text"},"cell_type":"markdown","source":["### Объявляем keras-модель."]},{"metadata":{"id":"T2v5A7pIj4tJ","colab_type":"code","colab":{}},"cell_type":"code","source":["max_sequence_len = 40\n","layers = 4\n","hidden_layers = 128\n","use_dropout = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BOesFPTllLyW","colab_type":"code","colab":{}},"cell_type":"code","source":["def create_model(predictors, label, max_sequence_len, total_words):\n","    input_len = max_sequence_len - 1\n","    model = Sequential()\n","    for i in range(layers-1):\n","      model.add(Bidirectional(CuDNNLSTM(hidden_layers, return_sequences=True)))\n","    model.add(Bidirectional(CuDNNLSTM(hidden_layers)))\n","    if use_dropout:\n","      model.add(Dropout(0.1))\n","    model.add(Dense(total_words, activation='softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uy8qJP1DA9oN","colab_type":"text"},"cell_type":"markdown","source":["### Объявляем вспомогательные функции"]},{"metadata":{"id":"pbiZSeiXJgXO","colab_type":"code","colab":{}},"cell_type":"code","source":["def sample(preds, temperature=1.0):\n","    \"\"\"\n","    Вспомогательная функция для выбора индекса элемента из массива предсказаний.\n","    preds: предсказания модели\n","    temperature: коэффициент, определяющий насколько креативны предсказывания модели\n","    \"\"\"\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","def on_epoch_end(epoch, logs):\n","    \"\"\"Вызывается в конце эпохи. Генерирует текст\"\"\"\n","    \n","    if epoch+1 == 1 or epoch+1 == 15:\n","        print()\n","        print('----- Сгенерированный текст после эпохи: %d' % epoch)\n","\n","        start_index = random.randint(0, len(data) - maxlen - 1)\n","        for temperature in [0.2, 0.5, 1.0, 1.2]:\n","            print('----- temperature:', temperature)\n","\n","            generated = ''\n","            sentence = data[start_index: start_index + maxlen]\n","            generated += sentence\n","            print('----- : \"' + sentence + '\"')\n","            sys.stdout.write(generated)\n","\n","            for i in range(400):\n","                x_pred = np.zeros((1, maxlen, len(chars)))\n","                for t, char in enumerate(sentence):\n","                    x_pred[0, t, char_indices[char]] = 1.\n","\n","                preds = model.predict(x_pred, verbose=0)[0]\n","                next_index = sample(preds, temperature)\n","                next_char = indices_char[next_index]\n","\n","                generated += next_char\n","                sentence = sentence[1:] + next_char\n","\n","                sys.stdout.write(next_char)\n","                sys.stdout.flush()\n","            print()\n","    else:\n","        print()\n","        print('----- Не генерируем текст после эпохи: %d' % epoch)\n","\n","generate_text = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","def generate(sentence='', length=400, temperature=1.0):\n","  \"\"\"Генерирует текст длинной length, начинающийся с sentence\"\"\"\n","  sentence = sentence.rjust(maxlen)[:maxlen].lower()\n","  generated = ''\n","  generated += sentence\n","\n","  for i in range(length):\n","    x_pred = np.zeros((1, maxlen, len(chars)))\n","    for t, char in enumerate(sentence):\n","      x_pred[0, t, char_indices[char]] = 1.\n","\n","    preds = model.predict(x_pred, verbose=0)[0]\n","    next_index = sample(preds, temperature)\n","    next_char = indices_char[next_index]\n","\n","    generated += next_char\n","    sentence = sentence[1:] + next_char\n","\n","  return generated"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gPn6eJVfBSti","colab_type":"text"},"cell_type":"markdown","source":["### Открытие и обработка датасета"]},{"metadata":{"id":"0bVau919lUhU","colab_type":"code","colab":{}},"cell_type":"code","source":["data = open('h2.txt', 'r').read()\n","\n","print(\"Всего %d символов\" % len(data))\n","data = data.lower()\n","chars = sorted(list(set(data)))\n","print('Всего уникальных символов:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))\n","maxlen = 40\n","step = 3\n","sentences = []\n","next_chars = []\n","for i in range(0, len(data) - maxlen, step):\n","    sentences.append(data[i: i + maxlen])\n","    next_chars.append(data[i + maxlen])\n","print('Всего последовательностей:', len(sentences), \"\\n\")\n","\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dh44B_a2rz8p","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zgnq2RqDBesd","colab_type":"text"},"cell_type":"markdown","source":["### Тренировка модели"]},{"metadata":{"id":"uIGf3woIl1zt","colab_type":"code","colab":{}},"cell_type":"code","source":["model = create_model(x, y, maxlen, len(chars))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cA1eAykyKM4b","colab_type":"code","colab":{}},"cell_type":"code","source":["# Чекпоинты. Для сохранения весов и настроек сети\n","filepath = \"weights.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, \n","                             monitor='loss', \n","                             verbose=1, \n","                             save_best_only=True, \n","                             mode='min')\n","if not new_model:\n","  model = load_model(weights_path)#TODO: разобраться почему не работает\n","\n","else:\n","  model.fit(x, y,\n","          batch_size=256,\n","          epochs=20,\n","          verbose=1,\n","          callbacks=[generate_text, checkpoint])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y13L-Zu0BjQf","colab_type":"text"},"cell_type":"markdown","source":["### Играемся"]},{"metadata":{"id":"1l_XHaZnoaWu","colab_type":"code","colab":{}},"cell_type":"code","source":["print(generate(\"парень с девушкой приходят после свидания к нему домой. Он достает ключи, а девушка ему говорит: \", temperature=0.1, length=500))\n","#on_epoch_end(0,\"\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Ok1i8eAHww7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}